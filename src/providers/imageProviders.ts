/**
 * Image Providers - AI Gateway Integration
 *
 * All image generation now routes through Vercel's AI Gateway for unified
 * model inference, billing, and management.
 *
 * Supported providers via gateway:
 * - OpenAI (gpt-image-1)
 * - Google Gemini (gemini-3-pro-image)
 *
 * FAL.ai remains as direct API calls (not supported by AI Gateway)
 */

import { generateText } from 'ai';
import { gateway } from '../config/gateway.js';
import {
  getFalAIKey,
  encodeImageToBase64,
  downloadAndSaveImage,
  saveBase64Image,
  makeHTTPRequest,
} from '../utils/imageUtils.js';
import path from 'path';
import fs from 'fs';

// Export helper functions from imageHelpers for external use
export {
  generateImage,
  generateMultipleImages,
  generateImageComparison,
  validateImageOptions,
  getDefaultOptions,
  mergeWithDefaults,
  type ImageGenerationOptions,
} from './imageHelpers.js';

/**
 * Gateway model mappings for each provider
 */
const GATEWAY_MODELS = {
  openai: 'openai/gpt-image-1',
  gemini: 'google/gemini-3-pro-image',
} as const;

/**
 * OpenAI Image Generation via AI Gateway
 *
 * Uses generateText with gpt-image-1 model through the unified gateway
 */
export const openaiGenerateImage = async (args: {
  prompt: string;
  outputPath: string;
  inputImagePath?: string;
  size?: '1024x1024' | '1792x1024' | '1024x1792';
  quality?: 'standard' | 'hd';
  style?: 'vivid' | 'natural';
  n?: number;
}): Promise<string> => {
  const isEditing = !!args.inputImagePath;

  console.error(`[Gateway/OpenAI] Generating image with model: ${GATEWAY_MODELS.openai}`);
  console.error(`[Gateway/OpenAI] Prompt: ${args.prompt}`);

  try {
    // Build messages array
    const content: any[] = [{ type: 'text', text: args.prompt }];

    // Add input image for editing
    if (isEditing && args.inputImagePath) {
      const imageData = fs.readFileSync(args.inputImagePath);
      const ext = path.extname(args.inputImagePath).toLowerCase();
      const mediaType = ext === '.jpg' || ext === '.jpeg' ? 'image/jpeg' : 'image/png';

      content.push({
        type: 'file',
        mediaType,
        data: imageData,
      });
    }

    const result = await generateText({
      model: gateway(GATEWAY_MODELS.openai),
      messages: [
        {
          role: 'user',
          content,
        },
      ],
    });

    // Save generated images
    const savedPaths: string[] = [];
    const imageFiles = result.files?.filter((f) => f.mediaType?.startsWith('image/')) || [];

    if (imageFiles.length === 0) {
      throw new Error('No images were generated by OpenAI');
    }

    // Create output directory if needed
    const dir = path.dirname(args.outputPath);
    if (!fs.existsSync(dir)) {
      fs.mkdirSync(dir, { recursive: true });
    }

    for (let i = 0; i < imageFiles.length; i++) {
      const file = imageFiles[i];
      let finalOutputPath = args.outputPath;

      // If multiple images, add index to filename
      if (imageFiles.length > 1) {
        const ext = path.extname(args.outputPath) || '.png';
        const baseName = path.basename(args.outputPath, ext);
        const outputDir = path.dirname(args.outputPath);
        finalOutputPath = path.join(outputDir, `${baseName}_${i + 1}${ext}`);
      }

      // Save the image
      if (file.base64) {
        saveBase64Image(file.base64, finalOutputPath);
        savedPaths.push(finalOutputPath);
      } else if (file.uint8Array) {
        fs.writeFileSync(finalOutputPath, file.uint8Array);
        savedPaths.push(finalOutputPath);
      }
    }

    return JSON.stringify({
      provider: 'OpenAI (via AI Gateway)',
      model: GATEWAY_MODELS.openai,
      operation: isEditing ? 'edit' : 'generate',
      savedPaths: savedPaths,
      prompt_used: args.prompt,
      text_response: result.text || null,
      usage: result.usage,
    });
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    throw new Error(`OpenAI image generation via Gateway failed: ${errorMessage}`);
  }
};

/**
 * Gemini Native Image Generation via AI Gateway
 *
 * Uses generateText with gemini-3-pro-image model through the unified gateway
 * Supports multiple input images for variations/combinations
 */
export const geminiGenerateImage = async (args: {
  prompt: string;
  outputPath: string;
  inputImagePaths?: string[];
  model?: string;
}): Promise<string> => {
  // Use provided model or default to gateway Gemini model
  const modelId = args.model || GATEWAY_MODELS.gemini;

  console.error(`[Gateway/Gemini] Generating image with model: ${modelId}`);
  console.error(`[Gateway/Gemini] Prompt: ${args.prompt}`);

  try {
    // Build content array
    const content: any[] = [{ type: 'text', text: args.prompt }];

    // Add input images if provided
    if (args.inputImagePaths && args.inputImagePaths.length > 0) {
      for (const imagePath of args.inputImagePaths) {
        const imageData = fs.readFileSync(imagePath);
        const ext = path.extname(imagePath).toLowerCase();
        const mediaType = ext === '.jpg' || ext === '.jpeg' ? 'image/jpeg' : 'image/png';

        content.push({
          type: 'file',
          mediaType,
          data: imageData,
        });
      }
    }

    const result = await generateText({
      model: gateway(modelId),
      messages: [
        {
          role: 'user',
          content,
        },
      ],
    });

    // Save generated images
    const savedPaths: string[] = [];
    const imageFiles = result.files?.filter((f) => f.mediaType?.startsWith('image/')) || [];

    if (imageFiles.length === 0) {
      throw new Error('No images were generated by Gemini');
    }

    // Create output directory if needed
    const dir = path.dirname(args.outputPath);
    if (!fs.existsSync(dir)) {
      fs.mkdirSync(dir, { recursive: true });
    }

    for (let i = 0; i < imageFiles.length; i++) {
      const file = imageFiles[i];
      let finalOutputPath = args.outputPath;

      // If multiple images, add index to filename
      if (imageFiles.length > 1) {
        const ext = path.extname(args.outputPath) || '.png';
        const baseName = path.basename(args.outputPath, ext);
        const outputDir = path.dirname(args.outputPath);
        finalOutputPath = path.join(outputDir, `${baseName}_${i + 1}${ext}`);
      }

      // Save the image
      if (file.base64) {
        saveBase64Image(file.base64, finalOutputPath);
        savedPaths.push(finalOutputPath);
      } else if (file.uint8Array) {
        fs.writeFileSync(finalOutputPath, file.uint8Array);
        savedPaths.push(finalOutputPath);
      }
    }

    return JSON.stringify({
      provider: 'Google Gemini (via AI Gateway)',
      model: modelId,
      operation: 'generate',
      savedPaths: savedPaths,
      prompt_used: args.prompt,
      input_images: args.inputImagePaths || [],
      text_response: result.text || null,
      usage: result.usage,
    });
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    throw new Error(`Gemini image generation via Gateway failed: ${errorMessage}`);
  }
};

/**
 * FAL.ai Image Generation (Direct API)
 *
 * FAL.ai is not supported by AI Gateway, so we use direct API calls.
 * Uses Qwen image generation model.
 */
export const falaiGenerateImage = async (args: {
  prompt: string;
  outputPath: string;
  image_size?:
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9';
  num_inference_steps?: number;
  guidance_scale?: number;
}): Promise<string> => {
  const apiKey = getFalAIKey();

  console.error(`[FAL.ai Direct] Generating image with model: qwen-image`);
  console.error(`[FAL.ai Direct] Prompt: ${args.prompt}`);

  const body = {
    prompt: args.prompt,
    image_size: args.image_size || 'square_hd',
    num_inference_steps: args.num_inference_steps || 20,
    guidance_scale: args.guidance_scale || 7.5,
    enable_safety_checker: true,
  };

  const headers = {
    Authorization: `Key ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const endpoint = 'https://fal.run/fal-ai/qwen-image';

  const response = await makeHTTPRequest(endpoint, 'POST', headers, body);

  if (response.error || response.detail) {
    throw new Error(
      `FAL.ai API error: ${response.error?.message || JSON.stringify(response.detail || response.error)}`
    );
  }

  // Save generated image
  const savedPaths: string[] = [];

  // Create output directory if needed
  const dir = path.dirname(args.outputPath);
  if (!fs.existsSync(dir)) {
    fs.mkdirSync(dir, { recursive: true });
  }

  if (response.images && response.images.length > 0) {
    const image = response.images[0];
    if (image.url) {
      await downloadAndSaveImage(image.url, args.outputPath);
      savedPaths.push(args.outputPath);
    } else {
      throw new Error('No image URL in FAL.ai response');
    }
  } else {
    throw new Error('No images array in FAL.ai response');
  }

  return JSON.stringify({
    provider: 'FAL.ai (Direct API)',
    model: 'qwen-image',
    operation: 'generate',
    savedPaths: savedPaths,
    prompt_used: args.prompt,
    seed: response.seed,
    inference_time: response.timings?.inference,
    parameters: body,
  });
};

/**
 * FAL.ai Image Editing (Direct API)
 *
 * FAL.ai is not supported by AI Gateway, so we use direct API calls.
 * Uses Qwen image editing model.
 */
export const falaiEditImage = async (args: {
  prompt: string;
  inputImagePath: string;
  outputPath: string;
  image_size?:
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9';
  num_inference_steps?: number;
  guidance_scale?: number;
}): Promise<string> => {
  const apiKey = getFalAIKey();

  console.error(`[FAL.ai Direct] Editing image with model: qwen-image-edit`);
  console.error(`[FAL.ai Direct] Prompt: ${args.prompt}`);

  // For now, use base64 inline (we can optimize later with proper upload)
  const imageBase64 = encodeImageToBase64(args.inputImagePath);

  const body = {
    prompt: args.prompt,
    image_url: `data:image/png;base64,${imageBase64}`,
    image_size: args.image_size || 'square_hd',
    num_inference_steps: args.num_inference_steps || 20,
    guidance_scale: args.guidance_scale || 7.5,
    enable_safety_checker: true,
  };

  const headers = {
    Authorization: `Key ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const endpoint = 'https://fal.run/fal-ai/qwen-image-edit';

  const response = await makeHTTPRequest(endpoint, 'POST', headers, body);

  if (response.error || response.detail) {
    throw new Error(
      `FAL.ai API error: ${response.error?.message || JSON.stringify(response.detail || response.error)}`
    );
  }

  // Save edited image
  const savedPaths: string[] = [];

  // Create output directory if needed
  const dir = path.dirname(args.outputPath);
  if (!fs.existsSync(dir)) {
    fs.mkdirSync(dir, { recursive: true });
  }

  if (response.images && response.images.length > 0) {
    const image = response.images[0];
    if (image.url) {
      await downloadAndSaveImage(image.url, args.outputPath);
      savedPaths.push(args.outputPath);
    } else {
      throw new Error('No image URL in FAL.ai edit response');
    }
  } else {
    throw new Error('No images array in FAL.ai edit response');
  }

  return JSON.stringify({
    provider: 'FAL.ai (Direct API)',
    model: 'qwen-image-edit',
    operation: 'edit',
    savedPaths: savedPaths,
    prompt_used: args.prompt,
    input_image: args.inputImagePath,
    seed: response.seed,
    inference_time: response.timings?.inference,
    parameters: body,
  });
};

/**
 * Helper function to generate with any provider
 * Routes OpenAI/Gemini through gateway, FAL.ai direct
 */
export const generateWithProvider = async (
  provider: 'openai' | 'gemini' | 'falai',
  prompt: string,
  outputPath: string,
  inputImagePaths?: string[]
): Promise<string> => {
  // Import the new helper function
  const { generateImage } = await import('./imageHelpers.js');

  return await generateImage({
    provider,
    prompt,
    outputPath,
    inputImagePaths,
  });
};

/**
 * Character Sheet Generation Tool
 * Uses AI Gateway for OpenAI/Gemini providers
 */
export const generateCharacterSheet = async (args: {
  characterDescription: string;
  outputPath: string;
  referenceImagePaths?: string[];
  model?: 'openai' | 'gemini' | 'falai';
  style?: string;
  includeExpressions?: boolean;
  includePoses?: boolean;
}): Promise<string> => {
  const model = args.model || 'gemini';
  const style = args.style || 'detailed digital art';

  // Build comprehensive character sheet prompt
  let prompt = `Create a detailed character sheet for: ${args.characterDescription}. `;
  prompt += `Art style: ${style}. `;

  if (args.includeExpressions) {
    prompt += 'Include multiple facial expressions (happy, sad, angry, surprised, neutral). ';
  }

  if (args.includePoses) {
    prompt += 'Show the character from multiple angles (front view, side view, back view). ';
  }

  prompt += 'Character sheet format with clean white background, professional reference sheet layout, ';
  prompt += 'consistent character design, high quality digital artwork suitable for animation or game development.';

  if (args.referenceImagePaths && args.referenceImagePaths.length > 0) {
    prompt +=
      ' Base the character on the provided reference images, maintaining consistency with the visual style and features shown.';
  }

  try {
    // Import the new helper function
    const { generateImage } = await import('./imageHelpers.js');

    const result = await generateImage({
      provider: model,
      prompt,
      outputPath: args.outputPath,
      inputImagePaths: args.referenceImagePaths,
    });

    const parsedResult = JSON.parse(result);

    return JSON.stringify({
      ...parsedResult,
      operation: 'character_sheet_generation',
      character_description: args.characterDescription,
      style: style,
      features: {
        expressions: args.includeExpressions || false,
        poses: args.includePoses || false,
      },
      reference_images: args.referenceImagePaths || [],
    });
  } catch (error) {
    throw new Error(
      `Character sheet generation failed: ${error instanceof Error ? error.message : String(error)}`
    );
  }
};

/**
 * Character Variation Tool
 * Uses AI Gateway for OpenAI/Gemini providers
 */
export const generateCharacterVariation = async (args: {
  prompt: string;
  outputPath: string;
  referenceImagePaths: string[];
  model?: 'openai' | 'gemini' | 'falai';
}): Promise<string> => {
  const model = args.model || 'gemini';

  if (!args.referenceImagePaths || args.referenceImagePaths.length === 0) {
    throw new Error('At least one reference image is required for character variation');
  }

  let prompt = args.prompt;
  prompt += ' Maintain consistency with the character design from the reference images. ';
  prompt += 'High quality digital artwork with consistent lighting and style.';

  try {
    // Import the new helper function
    const { generateImage } = await import('./imageHelpers.js');

    const result = await generateImage({
      provider: model,
      prompt,
      outputPath: args.outputPath,
      inputImagePaths: args.referenceImagePaths,
    });

    const parsedResult = JSON.parse(result);

    return JSON.stringify({
      ...parsedResult,
      operation: 'character_variation',
      variation_prompt: args.prompt,
      reference_images: args.referenceImagePaths,
    });
  } catch (error) {
    throw new Error(
      `Character variation generation failed: ${error instanceof Error ? error.message : String(error)}`
    );
  }
};

/**
 * Pixel Art Character Generation
 * Uses AI Gateway for OpenAI/Gemini providers
 */
export const generatePixelArtCharacter = async (args: {
  characterDescription: string;
  outputPath: string;
  pixelDimensions: '8x8' | '16x16' | '32x32' | '48x48' | '64x64' | '96x96';
  spriteSheet?: boolean;
  model?: 'openai' | 'gemini' | 'falai';
  colors?: number;
  transparentBackground?: boolean;
  backgroundColor?: 'white' | 'black' | 'auto';
}): Promise<string> => {
  const model = args.model || 'falai';
  const targetSize = parseInt(args.pixelDimensions.split('x')[0]);

  // Note: AI models may not generate accurate small pixel art directly
  // We generate at 256x256 in pixel art style, then would scale down post-processing
  const generationSize = 256; // Always generate larger first

  let prompt = `Pixel art character: ${args.characterDescription}. `;
  prompt += `Retro game pixel art style, limited color palette`;
  if (args.colors) {
    prompt += ` with ${args.colors} colors`;
  }
  prompt += `, clean pixels, no anti-aliasing, 8-bit/16-bit game style. `;

  // For transparent backgrounds, specify isolated character
  if (args.transparentBackground) {
    prompt += 'Character isolated on solid background, clean edges, no background details, ';
  }

  if (args.spriteSheet) {
    prompt += 'Generate as sprite sheet with multiple poses: idle, walking animation frames (4 frames), ';
    prompt += 'facing front, back, left, right. Grid layout on single image. ';
  }

  prompt += `Target final size will be ${args.pixelDimensions} pixels. `;
  prompt += 'Sharp pixel boundaries, retro gaming aesthetic, solid colors.';

  try {
    // Import the new helper function
    const { generateImage } = await import('./imageHelpers.js');

    // Generate at higher resolution first
    const tempPath = args.outputPath.replace(/\.[^.]+$/, '_temp_256px.png');

    const result = await generateImage({
      provider: model,
      prompt,
      outputPath: tempPath,
      transparentBackground: args.transparentBackground,
      backgroundColor: args.backgroundColor,
      transparencyTolerance: 20, // Lower tolerance for cleaner pixel art edges
      transparencyBlur: 0, // No blur for pixel art
    });

    const parsedResult = JSON.parse(result);

    let note = `Generated at ${generationSize}x${generationSize}px. Recommend scaling down to ${targetSize}x${targetSize}px and applying pixel-perfect scaling for final use.`;
    if (args.transparentBackground) {
      note += ' Sprite has transparent background for game use.';
    }

    return JSON.stringify({
      ...parsedResult,
      operation: 'pixel_art_generation',
      character_description: args.characterDescription,
      pixel_dimensions: args.pixelDimensions,
      target_size: targetSize,
      generation_size: generationSize,
      sprite_sheet: args.spriteSheet || false,
      colors: args.colors || 'auto',
      transparent_background: args.transparentBackground || false,
      temp_path: tempPath,
      note: note,
    });
  } catch (error) {
    throw new Error(
      `Pixel art generation failed: ${error instanceof Error ? error.message : String(error)}`
    );
  }
};

/**
 * 3D Texture Generation
 * Uses AI Gateway for OpenAI/Gemini providers
 */
export const generateTexture = async (args: {
  textureDescription: string;
  outputPath: string;
  textureSize?: '512x512' | '1024x1024' | '2048x2048';
  seamless?: boolean;
  model?: 'openai' | 'gemini' | 'falai';
  materialType?: 'diffuse' | 'normal' | 'roughness' | 'displacement';
  transparentBackground?: boolean;
  backgroundColor?: 'white' | 'black' | 'auto';
  transparencyTolerance?: number;
}): Promise<string> => {
  const model = args.model || 'falai';
  const textureSize = args.textureSize || '1024x1024';
  const materialType = args.materialType || 'diffuse';

  let prompt = `${materialType} texture map: ${args.textureDescription}. `;
  prompt += `High quality ${textureSize} texture, `;

  if (args.seamless) {
    prompt += 'seamless tileable pattern, repeating texture, no visible seams when tiled, ';
  }

  // For transparent backgrounds, modify the prompt for sprite/decal style textures
  if (args.transparentBackground) {
    prompt += 'sprite/decal style, ';
    if (materialType === 'diffuse') {
      prompt += 'isolated object with transparent background, clean edges, no shadows, ';
    }
  }

  switch (materialType) {
    case 'diffuse':
      if (args.transparentBackground) {
        prompt += 'color/albedo map with alpha transparency, object isolated on solid background';
      } else {
        prompt += 'color/albedo map, realistic material colors and details';
      }
      break;
    case 'normal':
      prompt += 'normal map, purple/blue surface detail information, height variation data';
      break;
    case 'roughness':
      prompt += 'roughness map, grayscale surface roughness information, white=rough, black=smooth';
      break;
    case 'displacement':
      prompt += 'displacement/height map, grayscale height information for 3D surface displacement';
      break;
  }

  prompt += `, professional game/3D development quality, uniform lighting`;
  if (!args.transparentBackground) {
    prompt += ', no shadows';
  }
  prompt += '.';

  try {
    // Import the new helper function
    const { generateImage } = await import('./imageHelpers.js');

    const result = await generateImage({
      provider: model,
      prompt,
      outputPath: args.outputPath,
      transparentBackground: args.transparentBackground,
      backgroundColor: args.backgroundColor,
      transparencyTolerance: args.transparencyTolerance,
      transparencyBlur: 1, // Slight blur for smoother edges
    });

    const parsedResult = JSON.parse(result);

    let usageNote =
      'Ready for use in 3D engines (Unity, Unreal, Blender). Apply to materials as ' +
      materialType +
      ' map.';
    if (args.transparentBackground) {
      usageNote += ' Texture has alpha transparency for sprites/decals.';
    }

    return JSON.stringify({
      ...parsedResult,
      operation: 'texture_generation',
      texture_description: args.textureDescription,
      texture_size: textureSize,
      material_type: materialType,
      seamless: args.seamless || false,
      transparent_background: args.transparentBackground || false,
      usage_note: usageNote,
    });
  } catch (error) {
    throw new Error(
      `Texture generation failed: ${error instanceof Error ? error.message : String(error)}`
    );
  }
};

/**
 * 3D Object Sheet Generation
 * Uses AI Gateway for OpenAI/Gemini providers
 */
export const generateObjectSheet = async (args: {
  objectDescription: string;
  outputBasePath: string;
  viewpoints?: ('front' | 'back' | 'left' | 'right' | 'top' | 'bottom' | 'perspective')[];
  model?: 'openai' | 'gemini' | 'falai';
  style?: string;
}): Promise<string> => {
  const model = args.model || 'gemini';
  const viewpoints = args.viewpoints || ['front', 'back', 'left', 'right', 'top', 'perspective'];
  const style = args.style || 'clean concept art';

  const results: any[] = [];
  const savedPaths: string[] = [];

  // Import the new helper function
  const { generateImage } = await import('./imageHelpers.js');

  for (const viewpoint of viewpoints) {
    const outputPath = args.outputBasePath.replace(/\.[^.]+$/, `_${viewpoint}.png`);

    let prompt = `${args.objectDescription}, ${viewpoint} view, `;
    prompt += `${style} style, technical reference sheet, `;
    prompt += `clean white background, object centered, `;

    switch (viewpoint) {
      case 'front':
        prompt += 'front-facing view, showing main features and details';
        break;
      case 'back':
        prompt += 'rear view, showing back details and construction';
        break;
      case 'left':
        prompt += 'left side profile view, showing side details and proportions';
        break;
      case 'right':
        prompt += 'right side profile view, showing opposite side details';
        break;
      case 'top':
        prompt += 'top-down view, showing overhead layout and proportions';
        break;
      case 'bottom':
        prompt += 'bottom-up view, showing underside construction';
        break;
      case 'perspective':
        prompt += '3/4 perspective view, showing depth and three-dimensional form';
        break;
    }

    prompt += '. Consistent object design, professional 3D reference quality.';

    try {
      const result = await generateImage({
        provider: model,
        prompt,
        outputPath,
      });

      const parsedResult = JSON.parse(result);
      results.push({
        viewpoint,
        result: parsedResult,
      });
      savedPaths.push(outputPath);
    } catch (error) {
      console.warn(`Failed to generate ${viewpoint} view:`, error);
      results.push({
        viewpoint,
        error: error instanceof Error ? error.message : String(error),
      });
    }
  }

  return JSON.stringify({
    operation: 'object_sheet_generation',
    object_description: args.objectDescription,
    viewpoints_requested: viewpoints,
    viewpoints_generated: results.filter((r) => !r.error).length,
    saved_paths: savedPaths,
    style: style,
    provider: model,
    results: results,
    usage_note: 'Use these reference images for 3D modeling. Import into Blender/Maya as reference planes.',
  });
};
